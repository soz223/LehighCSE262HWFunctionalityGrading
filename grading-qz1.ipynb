{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "with open('participants.txt') as f:\n",
    "    # peoples = f.readlines().remove('\\n')\n",
    "    peoples = f.read().splitlines()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # Loop through each email and extract the username part (before '@lehigh.edu')\n",
    "# for people in peoples: using tqdm to show the progress bar\n",
    "for people in tqdm(peoples):\n",
    "    \n",
    "    # Construct the GitLab repo URL using the email username\n",
    "    repo_url = f\"http://gitlab.cse.lehigh.edu/{people}-cse262/quiz-1\"\n",
    "    \n",
    "    # Call the Python script to check the repo\n",
    "    # You would use os.system() or subprocess to execute the shell command\n",
    "\n",
    "    # if exception occurs, print the error message\n",
    "    error = os.system(f\"python check_repo.py {repo_url}\")\n",
    "    if error:\n",
    "        print(f\"Repo for {people} is not good!\")\n",
    "        print(error)\n",
    "        continue\n",
    "    else:\n",
    "        # print(f\"Repo for {people} is good!\")\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the base directory where all the student folders are located\n",
    "base_dir = os.path.abspath(\"/home/soz223/cse262grading/repo/quiz-1\")  # Using absolute path to avoid relative path issues\n",
    "\n",
    "result_file_path = os.path.join(base_dir, \"results.txt\")\n",
    "\n",
    "# Ensure the results file exists\n",
    "if not os.path.exists(result_file_path):\n",
    "    with open(result_file_path, \"w\") as f:\n",
    "        f.write(\"\")  # Create the file if it doesn't exist\n",
    "\n",
    "# The standard answer for the quiz\n",
    "standard_answer = \"\"\"\n",
    "# CSE262 - Programming Languages - Fall 2024\n",
    "\n",
    "# Quiz 1\n",
    "\n",
    "Due: **9/9/2024 EOD**\n",
    "\n",
    "Make at least one commit per question. Write your answers in this file.\n",
    "\n",
    "## Question 1\n",
    "\n",
    "List all the programming languages you have used before, in order of preference. Comment on what you like/dislike about each.\n",
    "\n",
    "1. Python\n",
    "   - Like: Easy syntax, rich libraries.\n",
    "   - Dislike: Slower performance, dynamic typing issues.\n",
    "2. Rust\n",
    "   - Like: Memory safety, performance.\n",
    "   - Dislike: Steep learning curve, strict compiler rules.\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "# Function to grade a student's response using OpenAI API\n",
    "def grade_response(student_answer, standard_answer):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a grading assistant for Rust programming language assignments.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Standard Answer:\\n{standard_answer}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Student's Response:\\n{student_answer}\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"Please grade the student's response based on the following criteria:\\n\"\n",
    "            \"1. If the answer is mostly correct and covers all major points, give 100 points.\\n\"\n",
    "            \"2. If the answer is somewhat correct but incomplete or has minor mistakes, give 80-90 points.\\n\"\n",
    "            \"3. If the answer is given but mostly incorrect or off-topic, give 60-70 points.\\n\"\n",
    "            \"4. If the answer is blank or completely irrelevant, give 0 points.\\n\"\n",
    "            \"Be generous, give 100 to most people. For scores less than 100, explain why the points were deducted. \"\n",
    "            \"Provide the score and the reason in one line, reason must be specific, formatted as: 'Score: Reason for deduction'.\"\n",
    "        )}\n",
    "    ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=50,  # Allow more tokens to include the reason\n",
    "        temperature=0.0,  # Use a lower temperature for more deterministic responses\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "    \n",
    "    # Extracting the score and reason\n",
    "    result = response['choices'][0]['message']['content'].strip()\n",
    "    return result\n",
    "\n",
    "# Main function to loop through student directories and grade their quizzes\n",
    "def main():\n",
    "    # Example student folders list; this should be updated to the actual list of students\n",
    "    # student_folders = [\"student1\", \"student2\", \"student3\"]\n",
    "    # student_folders = [\"student1\", \"student2\", \"student3\"]\n",
    "    student_folders = peoples\n",
    "\n",
    "    # Array to track whether each student has been tested\n",
    "    is_test_array = [False] * len(student_folders)\n",
    "\n",
    "    # Iterate through each student folder\n",
    "    for idx, student_folder in enumerate(student_folders):\n",
    "        # Construct the path to the quiz-1 directory\n",
    "        hw1_folder = os.path.normpath(os.path.join(base_dir, student_folder + '-cse262', 'quiz-1'))\n",
    "\n",
    "        # Check if quiz-1 directory exists\n",
    "        if os.path.exists(hw1_folder):\n",
    "            # Path to README.md file\n",
    "            readme_file_path = os.path.join(hw1_folder, \"README.md\")\n",
    "\n",
    "            if os.path.exists(readme_file_path):\n",
    "                # Read the student's response from README.md\n",
    "                with open(readme_file_path, \"r\") as file:\n",
    "                    student_answer = file.read()\n",
    "\n",
    "                # Grade the student's response\n",
    "                result = grade_response(student_answer, standard_answer)\n",
    "\n",
    "                # Record the grade and reason in results.txt\n",
    "                with open(result_file_path, \"a\") as f:\n",
    "                    f.write(f\"{student_folder}: {result}\\n\")\n",
    "\n",
    "                print(f\"Graded {student_folder}: {result}\")\n",
    "                is_test_array[idx] = True\n",
    "            else:\n",
    "                print(f\"{student_folder} does not have a README.md file in the quiz-1 folder.\")\n",
    "                with open(result_file_path, \"a\") as f:\n",
    "                    f.write(f\"{student_folder} does not have a README.md file in the quiz-1 folder.\\n\")\n",
    "        else:\n",
    "            print(f\"{student_folder} does not have a quiz-1 folder.\")\n",
    "            with open(result_file_path, \"a\") as f:\n",
    "                f.write(f\"{student_folder} does not have a quiz-1 folder.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
